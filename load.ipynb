{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# %pip install \"modin[ray]\" # Install Modin dependencies and Ray.\n",
    "# import modin.pandas as pd\n",
    "# import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from data_processing import *\n",
    "\n",
    "# ray.init(num_cpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        day  item_id  warehouse_id  warehouse_city_id  total_begin_qty  \\\n",
      "0  20170605    34474            88                108                0   \n",
      "1  20170426    34474            88                108                0   \n",
      "2  20170414    34474            88                108                0   \n",
      "3  20170427    34474            88                108                0   \n",
      "4  20170425    34474            88                108                0   \n",
      "\n",
      "   total_end_qty  Replen_in_qty  transfer_in_qty  sale_out_qty  \\\n",
      "0              0              0                0             0   \n",
      "1              0              0                0             0   \n",
      "2              0              0                0             0   \n",
      "3              0              0                0             0   \n",
      "4              0              0                0             0   \n",
      "\n",
      "   transfer_out_qty  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = './data/data_8/msom_inventory_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"day\", \"item_id\", \"warehouse_id\", \"warehouse_city_id\",\n",
    "    \"total_begin_qty\", \"total_end_qty\", \"Replen_in_qty\",\n",
    "    \"transfer_in_qty\", \"sale_out_qty\", \"transfer_out_qty\"\n",
    "]\n",
    "\n",
    "inventory_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(inventory_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/data_8/msom_item_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"date\", \"item_id\", \"front_page_item_id\", \"merchant_id\", \"brand_id\",\n",
    "    \"category_id\", \"sub_category_id\", \"pc_pv\", \"app_pv\", \"pc_uv\", \"app_uv\",\n",
    "    \"if_cainiao\"\n",
    "]\n",
    "\n",
    "item_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(item_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/data_8/msom_seller_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"day\", \"merchant_id\", \"subcategory_id\", \"pc_pv\", \"pc_uv\", \"app_pv\", \"app_uv\",\n",
    "    \"avg_logistic_review_score\", \"avg_order_quality_score\", \"avg_service_quality_score\",\n",
    "    \"if_cainiao\"\n",
    "]\n",
    "\n",
    "seller_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(seller_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           order_id  order_date  logistics_order_id         action  \\\n",
      "76709      56910617    20170103            77281518  TRADE_SUCCESS   \n",
      "76710      56910617    20170103            77281518      DEPARTURE   \n",
      "76711      56910617    20170103            77281518        CONSIGN   \n",
      "76712      56910617    20170103            77281518            GOT   \n",
      "76713      56910617    20170103            77281518      DEPARTURE   \n",
      "...             ...         ...                 ...            ...   \n",
      "207159193  51308677    20170728            47361476      SENT_SCAN   \n",
      "207159194  51308677    20170728            47361476            GOT   \n",
      "207159195  51308677    20170728            47361476        CONSIGN   \n",
      "207159196  51308677    20170728            47361476         SIGNED   \n",
      "207159197  51308677    20170728            47361476  TRADE_SUCCESS   \n",
      "\n",
      "           facility_id  facility_type  city_id  logistic_company_id  \\\n",
      "76709              NaN            NaN      NaN                  674   \n",
      "76710          87761.0            2.0    157.0                  674   \n",
      "76711              NaN            NaN      NaN                  674   \n",
      "76712          46737.0            1.0    157.0                  674   \n",
      "76713          31084.0            1.0    157.0                  674   \n",
      "...                ...            ...      ...                  ...   \n",
      "207159193          NaN            NaN    144.0                  323   \n",
      "207159194          NaN            NaN    144.0                  323   \n",
      "207159195          NaN            NaN      NaN                  323   \n",
      "207159196          NaN            NaN    144.0                  323   \n",
      "207159197          NaN            NaN      NaN                  323   \n",
      "\n",
      "                     timestamp  timestamp_datetime  \n",
      "76709      2017-01-11 15:30:00 2017-01-11 15:30:00  \n",
      "76710      2017-01-04 22:27:00 2017-01-04 22:27:00  \n",
      "76711      2017-01-04 09:55:00 2017-01-04 09:55:00  \n",
      "76712      2017-01-04 18:00:00 2017-01-04 18:00:00  \n",
      "76713      2017-01-05 05:40:00 2017-01-05 05:40:00  \n",
      "...                        ...                 ...  \n",
      "207159193  2017-07-29 16:44:00 2017-07-29 16:44:00  \n",
      "207159194  2017-07-29 11:26:00 2017-07-29 11:26:00  \n",
      "207159195  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "207159196  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "207159197  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "\n",
      "[6658725 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/cleaned/data_7/cleaned_logistics_detail_7.feather'\n",
    "file_paths = [f'./data/cleaned/data_{i}/cleaned_logistics_detail_{i}.feather' for i in range(1, 8)]\n",
    "\n",
    "logistic_detail_data_list = []\n",
    "for path in file_paths:\n",
    "    logistic_detail_data_list.append(pd.read_feather(path))\n",
    "logistic_detail_data_df = pd.concat(logistic_detail_data_list)\n",
    "print(logistic_detail_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           order_id  order_date  logistics_order_id  action  facility_id  \\\n",
      "76709      56910617    20170103            77281518       6          NaN   \n",
      "76710      56910617    20170103            77281518       2      87761.0   \n",
      "76711      56910617    20170103            77281518       0          NaN   \n",
      "76712      56910617    20170103            77281518       1      46737.0   \n",
      "76713      56910617    20170103            77281518       2      31084.0   \n",
      "...             ...         ...                 ...     ...          ...   \n",
      "207159193  51308677    20170728            47361476       4          NaN   \n",
      "207159194  51308677    20170728            47361476       1          NaN   \n",
      "207159195  51308677    20170728            47361476       0          NaN   \n",
      "207159196  51308677    20170728            47361476       5          NaN   \n",
      "207159197  51308677    20170728            47361476       6          NaN   \n",
      "\n",
      "           facility_type  city_id  logistic_company_id            timestamp  \\\n",
      "76709                NaN      NaN                  674  2017-01-11 15:30:00   \n",
      "76710                2.0    157.0                  674  2017-01-04 22:27:00   \n",
      "76711                NaN      NaN                  674  2017-01-04 09:55:00   \n",
      "76712                1.0    157.0                  674  2017-01-04 18:00:00   \n",
      "76713                1.0    157.0                  674  2017-01-05 05:40:00   \n",
      "...                  ...      ...                  ...                  ...   \n",
      "207159193            NaN    144.0                  323  2017-07-29 16:44:00   \n",
      "207159194            NaN    144.0                  323  2017-07-29 11:26:00   \n",
      "207159195            NaN      NaN                  323  2017-07-29 16:45:00   \n",
      "207159196            NaN    144.0                  323  2017-07-29 16:45:00   \n",
      "207159197            NaN      NaN                  323  2017-07-29 16:45:00   \n",
      "\n",
      "           timestamp_datetime  \n",
      "76709     2017-01-11 15:30:00  \n",
      "76710     2017-01-04 22:27:00  \n",
      "76711     2017-01-04 09:55:00  \n",
      "76712     2017-01-04 18:00:00  \n",
      "76713     2017-01-05 05:40:00  \n",
      "...                       ...  \n",
      "207159193 2017-07-29 16:44:00  \n",
      "207159194 2017-07-29 11:26:00  \n",
      "207159195 2017-07-29 16:45:00  \n",
      "207159196 2017-07-29 16:45:00  \n",
      "207159197 2017-07-29 16:45:00  \n",
      "\n",
      "[6658725 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "logistic_detail_data_df = load_full_logistics_data()\n",
    "print(logistic_detail_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               day   order_id     item_det_info        pay_timestamp  \\\n",
      "7         20170101      14051  234001:1:1056.57  2017-01-01 00:02:00   \n",
      "55        20170101     113147   52906:1:1200.51  2017-01-01 00:00:00   \n",
      "94        20170101     187882    221985:1:93.21  2017-01-01 20:36:00   \n",
      "156       20170101     316717   171781:1:111.61  2017-01-01 10:52:00   \n",
      "173       20170101     343644  101198:1:1203.49  2017-01-01 12:22:00   \n",
      "...            ...        ...               ...                  ...   \n",
      "21077034  20170731  136355926  191620:1:3268.44  2017-07-31 16:04:00   \n",
      "21077096  20170731  136461014     163535:1:98.7  2017-07-31 22:08:00   \n",
      "21077226  20170731  136715344   190989:1:128.57  2017-07-31 20:00:00   \n",
      "21077386  20170731  137017761    31032:1:802.21  2017-07-31 18:56:00   \n",
      "21077452  20170731  137125516     77402:1:52.02  2017-07-31 10:11:00   \n",
      "\n",
      "          buyer_id  promise_speed  if_cainiao  merchant_id  \\\n",
      "7         83448593            2.0           1          505   \n",
      "55        15581379            3.0           1          505   \n",
      "94        56265450            2.0           1          286   \n",
      "156       27127510            3.0           1          153   \n",
      "173       37531927            2.0           1          133   \n",
      "...            ...            ...         ...          ...   \n",
      "21077034  28262181            2.0           1           72   \n",
      "21077096  43879317            NaN           1          323   \n",
      "21077226  13031905            3.0           1           65   \n",
      "21077386  50358402            3.0           1           42   \n",
      "21077452  65639190            1.0           1          312   \n",
      "\n",
      "          logistics_review_score pay_timestamp_datetime  \n",
      "7                            5.0    2017-01-01 00:02:00  \n",
      "55                           5.0    2017-01-01 00:00:00  \n",
      "94                           5.0    2017-01-01 20:36:00  \n",
      "156                          5.0    2017-01-01 10:52:00  \n",
      "173                          5.0    2017-01-01 12:22:00  \n",
      "...                          ...                    ...  \n",
      "21077034                     5.0    2017-07-31 16:04:00  \n",
      "21077096                     5.0    2017-07-31 22:08:00  \n",
      "21077226                     5.0    2017-07-31 20:00:00  \n",
      "21077386                     5.0    2017-07-31 18:56:00  \n",
      "21077452                     5.0    2017-07-31 10:11:00  \n",
      "\n",
      "[5774129 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/cleaned/data_7/cleaned_order_data_7.feather'\n",
    "file_paths = [f'./data/cleaned/data_{i}/cleaned_order_data_{i}.feather' for i in range(1, 8)]\n",
    "\n",
    "order_data_list = []\n",
    "for path in file_paths:\n",
    "    order_data_list.append(pd.read_feather(path))\n",
    "order_data_df = pd.concat(order_data_list)\n",
    "print(order_data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
