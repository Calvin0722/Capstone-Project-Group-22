{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# %pip install \"modin[ray]\" # Install Modin dependencies and Ray.\n",
    "# import modin.pandas as pd\n",
    "# import ray\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ray.init(num_cpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        day  item_id  warehouse_id  warehouse_city_id  total_begin_qty  \\\n",
      "0  20170605    34474            88                108                0   \n",
      "1  20170426    34474            88                108                0   \n",
      "2  20170414    34474            88                108                0   \n",
      "3  20170427    34474            88                108                0   \n",
      "4  20170425    34474            88                108                0   \n",
      "\n",
      "   total_end_qty  Replen_in_qty  transfer_in_qty  sale_out_qty  \\\n",
      "0              0              0                0             0   \n",
      "1              0              0                0             0   \n",
      "2              0              0                0             0   \n",
      "3              0              0                0             0   \n",
      "4              0              0                0             0   \n",
      "\n",
      "   transfer_out_qty  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your CSV file\n",
    "file_path = './data/data_8/msom_inventory_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"day\", \"item_id\", \"warehouse_id\", \"warehouse_city_id\",\n",
    "    \"total_begin_qty\", \"total_end_qty\", \"Replen_in_qty\",\n",
    "    \"transfer_in_qty\", \"sale_out_qty\", \"transfer_out_qty\"\n",
    "]\n",
    "\n",
    "inventory_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(inventory_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/data_8/msom_item_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"date\", \"item_id\", \"front_page_item_id\", \"merchant_id\", \"brand_id\",\n",
    "    \"category_id\", \"sub_category_id\", \"pc_pv\", \"app_pv\", \"pc_uv\", \"app_uv\",\n",
    "    \"if_cainiao\"\n",
    "]\n",
    "\n",
    "item_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(item_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/data_8/msom_seller_data.csv'\n",
    "\n",
    "column_names = [\n",
    "    \"day\", \"merchant_id\", \"subcategory_id\", \"pc_pv\", \"pc_uv\", \"app_pv\", \"app_uv\",\n",
    "    \"avg_logistic_review_score\", \"avg_order_quality_score\", \"avg_service_quality_score\",\n",
    "    \"if_cainiao\"\n",
    "]\n",
    "\n",
    "seller_data = pd.read_csv(file_path, names=column_names)\n",
    "# Display the first few rows of the DataFrame\n",
    "print(seller_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           order_id  order_date  logistics_order_id         action  \\\n",
      "106        75208908    20170114            48525288        ARRIVAL   \n",
      "107        75208908    20170114            48525288      SENT_SCAN   \n",
      "108        75208908    20170114            48525288        ARRIVAL   \n",
      "109        75208908    20170114            48525288         SIGNED   \n",
      "110        75208908    20170114            48525288        ARRIVAL   \n",
      "...             ...         ...                 ...            ...   \n",
      "207159193  51308677    20170728            47361476      SENT_SCAN   \n",
      "207159194  51308677    20170728            47361476            GOT   \n",
      "207159195  51308677    20170728            47361476        CONSIGN   \n",
      "207159196  51308677    20170728            47361476         SIGNED   \n",
      "207159197  51308677    20170728            47361476  TRADE_SUCCESS   \n",
      "\n",
      "           facility_id  facility_type  city_id  logistic_company_id  \\\n",
      "106                NaN            NaN      NaN                  247   \n",
      "107                NaN            NaN      NaN                  247   \n",
      "108                NaN            NaN      NaN                  247   \n",
      "109           176983.0            NaN      NaN                  247   \n",
      "110                NaN            NaN      NaN                  247   \n",
      "...                ...            ...      ...                  ...   \n",
      "207159193          NaN            NaN    144.0                  323   \n",
      "207159194          NaN            NaN    144.0                  323   \n",
      "207159195          NaN            NaN      NaN                  323   \n",
      "207159196          NaN            NaN    144.0                  323   \n",
      "207159197          NaN            NaN      NaN                  323   \n",
      "\n",
      "                     timestamp  timestamp_datetime  \n",
      "106        2017-01-15 16:38:00 2017-01-15 16:38:00  \n",
      "107        2017-01-18 21:06:00 2017-01-18 21:06:00  \n",
      "108        2017-01-18 21:01:00 2017-01-18 21:01:00  \n",
      "109        2017-01-18 21:14:00 2017-01-18 21:14:00  \n",
      "110        2017-01-17 13:33:00 2017-01-17 13:33:00  \n",
      "...                        ...                 ...  \n",
      "207159193  2017-07-29 16:44:00 2017-07-29 16:44:00  \n",
      "207159194  2017-07-29 11:26:00 2017-07-29 11:26:00  \n",
      "207159195  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "207159196  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "207159197  2017-07-29 16:45:00 2017-07-29 16:45:00  \n",
      "\n",
      "[52999484 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/cleaned/data_7/cleaned_logistics_detail_7.feather'\n",
    "file_paths = [f'./data/cleaned/data_{i}/cleaned_logistics_detail_{i}.feather' for i in range(1, 8)]\n",
    "\n",
    "logistic_detail_data_list = []\n",
    "for path in file_paths:\n",
    "    logistic_detail_data_list.append(pd.read_feather(path))\n",
    "logistic_detail_data_df = pd.concat(logistic_detail_data_list)\n",
    "print(logistic_detail_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               day   order_id     item_det_info        pay_timestamp  \\\n",
      "0         20170101        488   86889:1:1152.11  2017-01-01 13:07:00   \n",
      "7         20170101      14051  234001:1:1056.57  2017-01-01 00:02:00   \n",
      "12        20170101      21752    187237:1:64.39  2017-01-01 10:05:00   \n",
      "16        20170101      24101    184119:1:30.01  2017-01-01 20:01:00   \n",
      "43        20170101      83411     64416:1:96.77  2017-01-01 17:21:00   \n",
      "...            ...        ...               ...                  ...   \n",
      "21077034  20170731  136355926  191620:1:3268.44  2017-07-31 16:04:00   \n",
      "21077096  20170731  136461014     163535:1:98.7  2017-07-31 22:08:00   \n",
      "21077226  20170731  136715344   190989:1:128.57  2017-07-31 20:00:00   \n",
      "21077386  20170731  137017761    31032:1:802.21  2017-07-31 18:56:00   \n",
      "21077452  20170731  137125516     77402:1:52.02  2017-07-31 10:11:00   \n",
      "\n",
      "          buyer_id  promise_speed  if_cainiao  merchant_id  \\\n",
      "0         73376137            3.0           1          505   \n",
      "7         83448593            2.0           1          505   \n",
      "12        16664855            2.0           1          286   \n",
      "16        48797907            3.0           1          134   \n",
      "43        29020026            2.0           1           65   \n",
      "...            ...            ...         ...          ...   \n",
      "21077034  28262181            2.0           1           72   \n",
      "21077096  43879317            NaN           1          323   \n",
      "21077226  13031905            3.0           1           65   \n",
      "21077386  50358402            3.0           1           42   \n",
      "21077452  65639190            1.0           1          312   \n",
      "\n",
      "          logistics_review_score pay_timestamp_datetime  \n",
      "0                            5.0    2017-01-01 13:07:00  \n",
      "7                            5.0    2017-01-01 00:02:00  \n",
      "12                           4.0    2017-01-01 10:05:00  \n",
      "16                           5.0    2017-01-01 20:01:00  \n",
      "43                           5.0    2017-01-01 17:21:00  \n",
      "...                          ...                    ...  \n",
      "21077034                     5.0    2017-07-31 16:04:00  \n",
      "21077096                     5.0    2017-07-31 22:08:00  \n",
      "21077226                     5.0    2017-07-31 20:00:00  \n",
      "21077386                     5.0    2017-07-31 18:56:00  \n",
      "21077452                     5.0    2017-07-31 10:11:00  \n",
      "\n",
      "[7122095 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = './data/cleaned/data_7/cleaned_order_data_7.feather'\n",
    "file_paths = [f'./data/cleaned/data_{i}/cleaned_order_data_{i}.feather' for i in range(1, 8)]\n",
    "\n",
    "order_data_list = []\n",
    "for path in file_paths:\n",
    "    order_data_list.append(pd.read_feather(path))\n",
    "order_data_df = pd.concat(order_data_list)\n",
    "print(order_data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
